{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b1ff9e3d4eaddb6bfbb4c1797684f0e3f75c341b"
   },
   "source": [
    "# Regression with Random Forest\n",
    "* make a Random Forest Regressor to predict the sale price of houses. \n",
    "\n",
    "\n",
    "\n",
    "https://www.kaggle.com/pollux751/housing-prices-regression-with-random-forest/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# First import all necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "# Import training/testing data\n",
    "df = pd.read_csv(\"data/train.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "02eb8a7373ea009578c2783d230f2a52e977cdb9"
   },
   "source": [
    "# Getting familiar with the dataset:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* print the isnull().sum of your data\n",
    "* if you cannot see all the 75 rows add this instruction before pd.options.display.max_rows = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7908199f7d167c35163b0c3e48a93c316fb85777"
   },
   "outputs": [],
   "source": [
    "pd.options.display.max_rows = 100\n",
    "# see some info\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***YOUR TURN***\n",
    "#### remove some columns that have too many missing values:\n",
    "'Alley', 'PoolQC', 'Fence', 'MiscFeature', 'FireplaceQu'\n",
    "and print the shape of the database after the removing operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***YOUR TURN*** remove the the id column as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we should also remove the id -\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deal with categorical data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### we still have both categorical data and missing values and we need to pay attention to this..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***YOUR TURN*** fill the df['LotFrontage'] with the median of the column \n",
    "* we did this in a previous notebook but if you don't rememeber how to do it try to google: 'how to fill missing value in pandas with the median of the column?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### YOUR TURN drop all the other nan values rows\n",
    "\n",
    "* NOTICE always check that the target column is included when you drop rows..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* chech again that we don't have any missing values at this point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create the targets and features\n",
    "\n",
    "***YOUR TURN*** create a targets variable with the sale price and features variable with the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consider the categorical data\n",
    "\n",
    "***YOUR TURN*** using get_dummies create the dummies columns for all the categorical features use also drop_first = true\n",
    "* there are few way you can achieve this.\n",
    "* the quickest one is to do pd.get_dummies directly on the features database and drop first\n",
    "* in the solution I went for the long solution, since I wanted to be sure that integers and float values were not considered as categorical. But I think is not necessary and if you go for the short way I believe is fine. Check both methods.. at the end we all should have 227 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9c0f390a3d26549ee4dea26ae82174f73b24679a"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c5fb5bbb1cf2ee147b024e658e6b0621ad34f593"
   },
   "source": [
    "## Train split\n",
    "\n",
    "***YOUR TURN*** import the library for splitting and split the data into training and setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f4214989c7262d00ee8644ea278a8ca9fea2fe91"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***YOUR TURN*** import from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "52a906c126956995c1554cc7d21422abd3fd2e93"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***YOUR TURN*** create the model and set the number of estimator and max_features (look at the manual to see what max features does)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***YOUR TURN*** fit the model with x_train andy_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "52cebb44c50788ea04e40309f5f87111c9199a97"
   },
   "outputs": [],
   "source": [
    "# Fit and test to see how accurate the algorithm is\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***YOUR TURN*** print the training score and the testing score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "52cebb44c50788ea04e40309f5f87111c9199a97"
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8c89f7ceabf2e471ed097a239068b27d98a7bb13",
    "collapsed": true
   },
   "source": [
    "# Predictions \n",
    "\n",
    "***YOUR TURN*** store the predictions in a variable called predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "097ba47fb37bb404442cfa7fe0345328b5d6db00",
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean Square Error Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***YOUR TURN*** import from sklearn.metrics import mean_squared_error and print the root of the MSE of the y_test and predictions, use np.sqrt for the square root."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "# insert code below\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tells us that the average error is 33000 dollars which makes sense if we look at the price values and the test accuracy of our model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features importance\n",
    "\n",
    "***YOUR TURN*** print the features importances\n",
    "\n",
    "* in the solution I show you how to put the features_importances into its own database so it is nicer to see in the output and also you can sort it by values.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
