{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "d31499e5-ebd1-e178-1ced-16f82608db96"
   },
   "source": [
    "https://www.kaggle.com/nsrose7224/crowdedness-at-the-campus-gym/downloads/data.csv/2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "d31499e5-ebd1-e178-1ced-16f82608db96"
   },
   "source": [
    "## Goals  REGRESSION task\n",
    "* Given a time of day (and maybe some other features, including weather), predict how crowded the gym will be.\n",
    "* Figure out which features are actually important, which are redundant.\n",
    "* I manually added noise and extra \"fake\" features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "61e8090a-db25-b4c6-3635-514217f78bb4"
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "2682c5c2-b2ab-d65f-9d39-6fd4b96d075a"
   },
   "outputs": [],
   "source": [
    "df=pd.read_csv('data/data.csv') #Replace it with your path where the data file is stored"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    # I CHANGED THE DATA by ADDING NOISE AND EXTRA FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "my_randoms = np.array([random.randint(0,100) for i in range(62184)])\n",
    "my_randoms = my_randoms /1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"fakeFeature1\"] = df[\"month\"] * df[\"hour\"]\n",
    "df[\"fakeFeature2\"] = df[\"is_weekend\"] + df[\"is_holiday\"]\n",
    "df[\"fakeFeature3\"] = df[\"is_weekend\"] - df[\"is_holiday\"]\n",
    "df[\"fakeFeature4\"] = df[\"temperature\"] * df[\"month\"]\n",
    "df[\"fakeFeature5\"] = df[\"hour\"] * df[\"hour\"]\n",
    "df[\"fakeFeature6\"] = df[\"temperature\"] * my_randoms\n",
    "df[\"fakeFeature7\"] = df[\"hour\"] * my_randoms * 0.1\n",
    "df[\"fakeFeature8\"] = df[\"temperature\"] * df[\"month\"] * my_randoms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "68fa682d-a05f-65d1-0f9b-e3adf58660be"
   },
   "outputs": [],
   "source": [
    "df.drop(\"date\", axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is the base model we want to improve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[\"number_people\"]  # all rows, label only\n",
    "X = df.drop(\"number_people\", axis = 1)\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y)\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "model = RandomForestRegressor()\n",
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "print (\" train \"  , model.score(x_train,y_train))\n",
    "print (\"test \"  , r2_score(model.predict(x_test),y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YOUR TURN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "68fa682d-a05f-65d1-0f9b-e3adf58660be"
   },
   "source": [
    "## create the X and y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* select df[\"number_people\"] for y and all the other columns for X (using df.drop(\"number_people\", axis = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "68fa682d-a05f-65d1-0f9b-e3adf58660be"
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "dfbae261-e10b-74fa-c330-ebfaad9c7bc4"
   },
   "source": [
    "## Feature Scaling X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "190f9d7e-9527-0a7a-1bb4-cc163016ffe3"
   },
   "source": [
    "* use from sklearn.preprocessing import StandardScaler\n",
    "* create the scaler object\n",
    "* fit_transform (X) and store the result back to X  so that X is scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "190f9d7e-9527-0a7a-1bb4-cc163016ffe3"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "190f9d7e-9527-0a7a-1bb4-cc163016ffe3"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "190f9d7e-9527-0a7a-1bb4-cc163016ffe3"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* from sklearn.decomposition import PCA\n",
    "* create an object called pca using PCA(n_components=10) or (0.80)\n",
    "* fit_transform(X) and store the result to a variable called X_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "985295c0-1ef4-5ddb-a048-e85cc21e2360"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "985295c0-1ef4-5ddb-a048-e85cc21e2360"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "985295c0-1ef4-5ddb-a048-e85cc21e2360"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "76356efb-11b9-3941-952d-c4a67d6a3e23"
   },
   "source": [
    "## Split the data \n",
    "\n",
    "* use from sklearn.model_selection import train_test_split to split the data into training and testing\n",
    "* remember to pass the x_pca not the original X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "76356efb-11b9-3941-952d-c4a67d6a3e23"
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* fit the model fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* print the score for training and  r2_score(model.predict(x_test),y_test)) for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* what is the effect of the PCA?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# try to improve the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "ce87ea95-ecb9-6efd-3edb-aad6f36b0c18"
   },
   "source": [
    "### Correlation between different fearures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* create the correlation matrix using df.corr()\n",
    "* add also the .abs() function so that minus and plus will be seen as the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "ce87ea95-ecb9-6efd-3edb-aad6f36b0c18"
   },
   "source": [
    "* create an heatmap using sns.heatmap with the correlation you created above , add ( annot= true) so you can see the value\n",
    "* add this line if you cannot see well the graph plt.figure(figsize=(20,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "ce87ea95-ecb9-6efd-3edb-aad6f36b0c18"
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## correlation to the target\n",
    "\n",
    "* use this code to print the features correlated to the target\n",
    "\n",
    "    *    print(correlation['number_people'].sort_values(ascending=False).head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "dfbae261-e10b-74fa-c330-ebfaad9c7bc4"
   },
   "source": [
    "##  features selection\n",
    "\n",
    "use the information above and..\n",
    "\n",
    "* decide what features to keep\n",
    "* create a new dataset by droping the column that you don't want\n",
    "* to drop a column :\n",
    "    * df.drop(\"column name\", axis = 1, inplace = True)\n",
    "* create again your X and y from this new dataset\n",
    "* normalised the data\n",
    "* decide if you want to do PCA\n",
    "* split the data\n",
    "* build the model - RandomForestRegressor\n",
    "* print the scores\n",
    "\n",
    "* make a note of your best training score and testing score.. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSERT YOUR CODES HERE\n",
    "# there are several lines to write... but most of them basically are the same as you just wrote above..\n",
    "# we will probably find yourself copying and pasting lines from above\n",
    "# if you want you can select multiple lines in jupyter notebooks and then paste\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "_change_revision": 0,
  "_is_fork": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
