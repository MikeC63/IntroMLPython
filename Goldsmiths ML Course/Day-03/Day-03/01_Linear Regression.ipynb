{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01 Linear Regression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "\n",
    "* Predict the house sales in King County, Washington State, USA. The dataset consisted of historic data of houses sold between May 2014 to May 2015. \n",
    "* https://www.kaggle.com/shivachandel/kc-house-data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse your Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* import the libraries that have the tools that we need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "# comment if not working"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Load data from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"data/kc_house_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# have a look at the first five rows\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with missing values\n",
    "dataset = dataset.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seaborn is another Python Library that makes plot of graph easier.\n",
    "* https://seaborn.pydata.org/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the library\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot the distribution of the target variable using distplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.distplot( dataset['price'] ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple analysis with one feature and one target\n",
    "# we select only 2 features.\n",
    "df = dataset[[\"sqft_living\", \"price\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(x=\"sqft_living\", y=\"price\", data=df, scatter_kws={'alpha':0.3})\n",
    "# this seaborn graph  has already a regression line in the graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The graph uses a statistical method to find the regression line (see presentation)\n",
    "* We want to use Scikit Learn Linear regression to model more complex dataset with more features \n",
    "* but for now we can implement the model for 1 feature and 1 target and see if it matches the plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create our reduced dataset with one feature and one target\n",
    "x = df['sqft_living']\n",
    "y = df['price']\n",
    "       \n",
    "print(x.shape)\n",
    "np.array(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape array x into a column vector\n",
    "x = np.array(x).reshape(-1, 1) # this is something to remember (reshape -1,1 if single column)\n",
    "print(x.shape,y.shape)\n",
    "\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create the model, fit the model, predition+visualisation (3 steps in one cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fitting simple linear regression to the Training Set\n",
    "from sklearn.linear_model import LinearRegression \n",
    "\n",
    "# create the model\n",
    "model = LinearRegression()\n",
    "\n",
    "# train the model\n",
    "model.fit(x, y)\n",
    "\n",
    "# prediction\n",
    "predictions = model.predict(x)\n",
    "\n",
    "#Visualizing training data and prediction one on top of the other\n",
    "plt.scatter(x, y)\n",
    "plt.plot(x, predictions, color='r')\n",
    "plt.xlabel(\"sqft_living\")\n",
    "plt.ylabel(\"Price\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id=\"4\"></a><br> Examining and Adding More Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we put all the features in a separate dataset\n",
    "features = ['bedrooms', 'bathrooms', 'sqft_living',\n",
    "            'sqft_lot', 'floors', 'waterfront', 'view', 'condition', 'grade',\n",
    "            'sqft_above', 'sqft_basement', 'yr_built', 'yr_renovated', 'zipcode',\n",
    "            'sqft_living15', 'sqft_lot15']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id=\"6\"></a><br> Complex Model \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets add all the features and set our target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = dataset[features]\n",
    "y = dataset['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the data into Train and Test\n",
    "from sklearn.model_selection import train_test_split \n",
    "xtrain, xtest, ytrain, ytest = train_test_split(x,y,random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new model\n",
    "complex_model_1 = LinearRegression()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complex_model_1.fit(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the model  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### make the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred1 = complex_model_1.predict(xtest)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "print (\"\\nCOMPLEX MODEL - 1\")\n",
    "print (\"features1: 'all the features' \")\n",
    "print('Intercept: {}'.format(complex_model_1.intercept_))\n",
    "print('Coefficients: {}'.format(complex_model_1.coef_))\n",
    "print ('rme (testing) {}'.format(np.sqrt(mean_squared_error(ytest, pred1))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "( For information on printing and the .format command, see: https://pyformat.info/ )\n",
    "\n",
    "## R2 score - proportion of variance in the output explained by our model \n",
    "\n",
    "\n",
    "0% indicates that the model explains none of the variability of the response data around its mean.\n",
    "100% indicates that the model explains all the variability of the response data around its mean.\n",
    "\n",
    "* r2-score is useful to compare models rather than as an accuracy metric for one regressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('score (training): {}'.format(complex_model_1.score(xtrain,ytrain)))\n",
    "# these two are the same\n",
    "print('score (test): {}'.format(complex_model_1.score(xtest,ytest)))\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "print('r2_score (test): {}'.format(r2_score(ytest, pred1)))\n",
    "\n",
    "complex_model_1.score\n",
    "print ('rme (testing) {}'.format(np.sqrt(mean_squared_error(ytest, pred1))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate the Pearson cross-correlation of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(16, 12))\n",
    "plt.title('Pearson Correlation Matrix',fontsize=25)\n",
    "\n",
    "sns.heatmap(dataset[features].corr(), linewidths=0.25, vmax=1.0, square=True, cmap=\"BuGn_r\", linecolor='k', annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(dataset[['sqft_living', 'sqft_above']])\n",
    "sns.pairplot(dataset[['sqft_living', 'sqft_living15']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* these features are not adding values to our model.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets remove some features (sqft_above and 'sqft_living15' )\n",
    "features2 = ['bedrooms', 'bathrooms', 'sqft_living',\n",
    "            'sqft_lot', 'floors', 'waterfront', 'view', 'condition', 'grade',\n",
    "            'sqft_basement', 'yr_built', 'yr_renovated', 'zipcode',\n",
    "             'sqft_lot15']\n",
    "x = dataset[features2]\n",
    "y = dataset['price']\n",
    "\n",
    "#Splitting the data into Train and Test\n",
    "from sklearn.model_selection import train_test_split \n",
    "xtrain, xtest, ytrain, ytest = train_test_split(x,y, random_state=0)\n",
    "complex_model_2 = LinearRegression()\n",
    "complex_model_2.fit(xtrain,ytrain)\n",
    "pred2 = complex_model_2.predict(xtest)\n",
    "\n",
    "print (\"\\nCOMPLEX MODEL - 2\")\n",
    "print (\"features2: without a couple of features\")\n",
    "print('Intercept: {}'.format(complex_model_2.intercept_))\n",
    "print('Coefficients: {}'.format(complex_model_2.coef_))\n",
    "print('score (training): {}'.format(complex_model_2.score(xtrain,ytrain)))\n",
    "print('score (test): {}'.format(complex_model_2.score(xtest,ytest)))\n",
    "print ('rme (testing) {}'.format(np.sqrt(mean_squared_error(ytest, pred2))))\n",
    "r2_score(ytest, pred2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* avoinding to use 2 features in our dataset changed the r2_score by a small amount - but it reduced the computational time\n",
    "* first rule : try to avoid features that don't add any additional information to help the prediction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coefficient (the slopes)\n",
    "* store the coefficient into a database so it easier to read the values\n",
    "* we use pd.DataFrame that creates a pandas dataframe from numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coeff_df = pd.DataFrame(data = complex_model_2.coef_, index = x.columns,columns=['Coefficient'])\n",
    "coeff_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpreting the coefficients:\n",
    "\n",
    "* Holding all other features fixed, a 1 unit increase in sqft_living is associated with an *increase of 17.19... * of the price\n",
    "* Holding all other features fixed, a 1 unit increase in yr_built is associated with an *decrease of 357.66... * of the price"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Residuals vs Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "residuals = ytest - pred2\n",
    "plt.scatter(pred2, residuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(residuals,bins=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the model by looking at the results instead of calculating the score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(ytest,pred2)\n",
    "plt.xlabel('Y Test')\n",
    "plt.ylabel('Predicted Y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a good situation would be to have most of the data along the diagonal.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OneExample = x.loc[17384]\n",
    "OneExample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictionFor17384 = complex_model_2.predict(np.array(OneExample).reshape(1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictionFor17384 - y.loc[17384] # in dollars.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib \n",
    "# We can make an interactive plot that we can zoom in on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import figure\n",
    "figure(num=None, figsize=(18, 8), )\n",
    "plt.plot(np.array(ytest))\n",
    "plt.plot(pred2)\n",
    "\n",
    "plt.show(figure)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* This confirms what was clear from the distribution of prices and the plot of the prediction vs true target. It seems there some non linearity going on?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
